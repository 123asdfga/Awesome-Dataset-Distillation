# Awesome-Dataset-Distillation
Awesome Dataset Distillation/Condensation Papers

Dataset distillation is the task of synthesizing a small dataset such that a model trained on the synthetic set will match the test accuracy of the model trained on the full dataset.

*The project was completed by [Guang Li](https://www-lmd.ist.hokudai.ac.jp/member/guang-li/) and [Tongzhou Wang](https://www.tongzhouwang.info/).

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
<img src="https://img.shields.io/badge/Contributions-Welcome-278ea5" alt="Contrib"/> <img src="https://img.shields.io/badge/Number%20of%20Papers-35-FF6F00" alt="PaperNum"/>

> :octocat: Code  ðŸ”¥ Hot

# Main
+ [ðŸ”¥Dataset Distillation](https://arxiv.org/abs/1811.10959) (Tongzhou Wang et al., 2018) [[Project Page]](https://ssnl.github.io/dataset_distillation/) [:octocat:](https://github.com/SsnL/dataset-distillation)
```
@article{wang2018dataset,
  title={Dataset Distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}
```
+ [Flexible Dataset Distillation: Learn Labels Instead of Images](https://arxiv.org/abs/2006.08572) (Ondrej Bohdal et al., NeurIPS2020 Workshop) [:octocat:](https://github.com/ondrejbohdal/label-distillation)
```
@inproceedings{bohdal2020flexible,
  title={Flexible Dataset Distillation: Learn Labels Instead of Images},
  author={Bohdal, Ondrej and Yang, Yongxin and Hospedales, Timothy},
  booktitle={Proceedings of the Advances in Neural Information Processing Systems (NeurIPS), Workshop},
  year={2020}
}
```
+ [Soft-Label Dataset Distillation and Text Dataset Distillation](https://arxiv.org/abs/1910.02551) (Ilia Sucholutsky et al., IJCNN2021) [:octocat:](https://github.com/ilia10000/dataset-distillation)
```
@inproceedings{sucholutsky2021soft,
  title={Soft-Label Dataset Distillation and Text Dataset Distillation},
  author={Sucholutsky, Ilia and Schonlau, Matthias},
  booktitle={Proceedings of the International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2021}
}
```
+ [ðŸ”¥Dataset Condensation with Gradient Matching](https://arxiv.org/abs/2006.05929) (Bo Zhao et al., ICLR2021) [:octocat:](https://github.com/VICO-UoE/DatasetCondensation)
```
@inproceedings{zhao2021dataset,
  title={Dataset Condensation with Gradient Matching},
  author={Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}
```
+ [Dataset Meta-Learning from Kernel Ridge-Regression](https://arxiv.org/abs/2011.00050) (Timothy Nguyen et al., ICLR2021) [:octocat:](https://github.com/google/neural-tangents)
```
@inproceedings{nguyen2021dataset,
  title={Dataset Meta-Learning from Kernel Ridge-Regression},
  author={Nguyen, Timothy and Chen, Zhourong and Lee, Jaehoon},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}
```
+ [Dataset Condensation with Differentiable Siamese Augmentation](https://arxiv.org/abs/2102.08259) (Bo Zhao et al., ICML2021)  [:octocat:](https://github.com/VICO-UoE/DatasetCondensation)
```
@inproceedings{zhao2021dataset,
  title={Dataset condensation with Differentiable Siamese Augmentation},
  author={Zhao, Bo and Bilen, Hakan},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={12674--12685},
  year={2021}
}
```
+ [Dataset Distillation with Infinitely Wide Convolutional Networks](https://arxiv.org/abs/2107.13034) (Timothy Nguyen et al., NeurIPS2021) [:octocat:](https://github.com/google/neural-tangents)
```
@inproceedings{nguyen2021dataset,
  title={Dataset Distillation with Infinitely Wide Convolutional Networks},
  author={Nguyen, Timothy and Novak, Roman and Xiao, Lechao and Lee, Jaehoon},
  booktitle={Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)},
  pages={5186--5198},
  year={2021}
}
```
+ [Dataset Condensation with Distribution Matching](https://arxiv.org/abs/2110.04181) (Bo Zhao et al., 2021) [:octocat:](https://github.com/VICO-UoE/DatasetCondensation)
```
@article{zhao2021dataset,
  title={Dataset Condensation with Distribution Matching},
  author={Zhao, Bo and Bilen, Hakan},
  journal={arXiv preprint arXiv:2110.04181},
  year={2021}
}
```
+ [ðŸ”¥Dataset Distillation by Matching Training Trajectories](https://arxiv.org/abs/2203.11932) (George Cazenavette et al., CVPR2022) [[Project Page]](https://georgecazenavette.github.io/mtt-distillation/) [:octocat:](https://github.com/georgecazenavette/mtt-distillation)
```
@inproceedings{cazenavette2022dataset,
  title={Dataset distillation by matching training trajectories},
  author={Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={4750--4759},
  year={2022}
}
```
+ [CAFE: Learning to Condense Dataset by Aligning Features](https://arxiv.org/abs/2203.01531) (Kai Wang et al., CVPR2022)  [:octocat:](https://github.com/kaiwang960112/cafe)
```
@inproceedings{wang2022cafe,
  title={CAFE: Learning to Condense Dataset by Aligning Features},
  author={Wang, Kai and Zhao, Bo and Peng, Xiangyu and Zhu, Zheng and Yang, Shuo and Wang, Shuo and Huang, Guan and Bilen, Hakan and Wang, Xinchao and You, Yang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={12196--12205},
  year={2022}
}
```
+ [Dataset Condensation with Contrastive Signals](https://arxiv.org/abs/2202.02916) (Saehyung Lee et al., ICML2022) [:octocat:](https://github.com/saehyung-lee/dcc)
```
@inproceedings{lee2022dataset,
  title={Dataset Condensation with Contrastive Signals},
  author={Lee, Saehyung and Chun, Sanghyuk and Jung, Sangwon and Yun, Sangdoo and Yoon, Sungroh},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={12352--12364},
  year={2022}
}
```
+ [Dataset Condensation via Efficient Synthetic-Data Parameterization](https://arxiv.org/abs/2205.14959) (Jang-Hyun Kim et al., ICML2022) [:octocat:](https://github.com/snu-mllab/efficient-dataset-condensation)
```
@inproceedings{kim2022dataset,
  title={Dataset Condensation via Efficient Synthetic-Data Parameterization},
  author={Kim, Jang-Hyun and Kim, Jinuk and Oh, Seong Joon and Yun, Sangdoo and Song, Hwanjun and Jeong, Joonhyun and Ha, Jung-Woo and Song, Hyun Oh},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={11102--11118},
  year={2022}
}
```
+ [Synthesizing Informative Training Samples with GAN](https://arxiv.org/abs/2204.07513) (Bo Zhao et al., 2022) [:octocat:](https://github.com/vico-uoe/it-gan)
```
@article{zhao2022synthesizing,
  title={Synthesizing Informative Training Samples with GAN},
  author={Zhao, Bo and Bilen, Hakan},
  journal={arXiv preprint arXiv:2204.07513},
  year={2022}
}
```
+ [Dataset Distillation using Neural Feature Regression](https://arxiv.org/abs/2206.00719) (Yongchao Zhou et al., 2022)
```
@article{zhou2022dataset,
  title={Dataset Distillation using Neural Feature Regression},
  author={Zhou, Yongchao and Nezhadarya, Ehsan and Ba, Jimmy},
  journal={arXiv preprint arXiv:2206.00719},
  year={2022}
}
```
+ [DC-BENCH: Dataset Condensation Benchmark](https://arxiv.org/abs/2207.09639) (Justin Cui et al., 2022) [:octocat:](https://github.com/justincui03/dc_benchmark)
```
@article{cui2022dc,
  title={DC-BENCH: Dataset Condensation Benchmark},
  author={Cui, Justin and Wang, Ruochen and Si, Si and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2207.09639},
  year={2022}
}
```

# Privacy
+ [Soft-Label Anonymous Gastric X-ray Image Distillation](https://arxiv.org/abs/2104.02857) (Guang Li et al., ICIP2020) [:octocat:](https://github.com/Guang000/Awesome-Dataset-Distillation)
```
@inproceedings{li2020soft,
  title={Soft-Label Anonymous Gastric X-Ray Image Distillation},
  author={Li, Guang and Togo, Ren and Ogawa, Takahiro and Haseyama, Miki},
  booktitle={Proceedings of the IEEE International Conference on Image Processing (ICIP)},
  pages={305--309},
  year={2020}
}
```
+ [SecDD: Efficient and Secure Method for Remotely Training Neural Networks](https://arxiv.org/abs/2009.09155) (Ilia Sucholutsky et al., AAAI2021 Student Abstract)
```
@inproceedings{sucholutsky2021secdd,
  title={SecDD: Efficient and Secure Method for Remotely Training Neural Networks},
  author={Sucholutsky, Ilia and Schonlau, Matthias},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  pages={15897--15898},
  year={2021}
}
```
+ [ðŸ”¥Privacy for Free: How does Dataset Condensation Help Privacy?](https://arxiv.org/abs/2206.00240) (Tian Dong et al., ICML2022, [Outstanding Paper Award](https://icml.cc/virtual/2022/awards_detail)) 
```
@inproceedings{dong2022privacy,
  title={Privacy for Free: How does Dataset Condensation Help Privacy?},
  author={Dong, Tian and Zhao, Bo and Liu, Lingjuan},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={5378--5396},
  year={2022}
}
```

# Federated Learning
+ [Federated Learning via Synthetic Data](https://arxiv.org/abs/2008.04489) (Jack Goetz et al., 2020)
```
@article{goetz2020federated,
  title={Federated Learning via Synthetic Data},
  author={Goetz, Jack and Tewari, Ambuj},
  journal={arXiv preprint arXiv:2008.04489},
  year={2020}
}
```
+ [Distilled One-Shot Federated Learning](https://arxiv.org/abs/2009.07999) (Yanlin Zhou et al., 2020)
```
@article{zhou2020distilled,
  title={Distilled One-Shot Federated Learning},
  author={Zhou, Yanlin and Pu, George and Ma, Xiyao and Li, Xiaolin and Wu, Dapeng},
  journal={arXiv preprint arXiv:2009.07999},
  year={2020}
}
```
+ [FedSynth: Gradient Compression via Synthetic Data in Federated Learning](https://arxiv.org/abs/2204.01273) (Shengyuan Hu et al., 2022)
```
@article{hu2022fedsynth,
  title={FedSynth: Gradient Compression via Synthetic Data in Federated Learning},
  author={Hu, Shengyuan and Goetz, Jack and Malik, Kshitiz and Zhan, Hongyuan and Liu, Zhe and Liu, Yue},
  journal={arXiv preprint arXiv:2204.01273},
  year={2022}
}
```
+ [FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning](https://arxiv.org/abs/2207.09653) (Yuanhao Xiong et al., 2022)
```
@article{xiong2022feddm,
  title={FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning},
  author={Xiong, Yuanhao and Wang, Ruochen and Cheng, Minhao and Yu, Felix and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2207.09653},
  year={2022}
}
```

# Continual Learning
+ [Reducing Catastrophic Forgetting with Learning on Synthetic Data](https://arxiv.org/abs/2004.14046) (Wojciech Masarczyk et al., CVPR2020 Workshop)
```
@inproceedings{masarczyk2020reducing,
  title={Reducing Catastrophic Forgetting with Learning on Synthetic Data},
  author={Masarczyk, Wojciech and Tautkute, Ivona},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Workshop},
  year={2020}
}
```
+ [Condensed Composite Memory Continual Learning](https://arxiv.org/abs/2102.09890) (Felix Wiewel et al., IJCNN2021) [:octocat:](https://github.com/FelixWiewel/CCMCL)
```
@inproceedings{Wiewel2021soft,
  title={Condensed Composite Memory Continual Learning},
  author={Wiewel, Felix and Yang, Bin},
  booktitle={Proceedings of the International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2021}
}
```
+ [Distilled Replay: Overcoming Forgetting through Synthetic Samples](https://arxiv.org/abs/2103.15851) (Andrea Rosasco, 2021) [:octocat:](https://github.com/andrearosasco/DistilledReplay)
```
@article{rosasco2021distilled,
  title={Distilled Replay: Overcoming Forgetting through Synthetic Samples},
  author={Rosasco, Andrea and Carta, Antonio and Cossu, Andrea and Lomonaco, Vincenzo and Bacciu, Davide},
  journal={arXiv preprint arXiv:2103.15851},
  year={2021}
}
```
+ [Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks](https://arxiv.org/abs/2206.02916) (Zhiwei Deng et al., 2022)
```
@article{deng2022remember,
  title={Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks},
  author={Deng, Zhiwei and Russakovsky, Olga},
  journal={arXiv preprint arXiv:2206.02916},
  year={2022}
}
```
+ [Sample Condensation in Online Continual Learning](https://arxiv.org/abs/2206.11849) (Mattia Sangermano et al., IJCNN2022)
```
@inproceedings{Sangermano2022sample,
  title={Sample Condensation in Online Continual Learning},
  author={Sangermano, Mattia and Carta, Antonio and Cossu, Andrea and Bacciu, Davide},
  booktitle={Proceedings of the International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022}
}
```

# Model Compression
+ [Compressed Gastric Image Generation Based on Soft-Label Dataset Distillation for Medical Data Sharing](https://www.journals.elsevier.com/computer-methods-and-programs-in-biomedicine) (Guang Li et al., CMPB2022)
```
@article{li2022compressed,
  title={Compressed Gastric Image Generation Based on Soft-Label Dataset Distillation for Medical Data Sharing},
  author={Li, Guang and Togo, Ren and Ogawa, Takahiro and Haseyama, Miki},
  journal={Computer Methods and Programs in Biomedicine},
  year={2022}
}
```
+ [PRANC: Pseudo RAndom Networks for Compacting deep models](https://arxiv.org/abs/2206.08464) (Parsa Nooralinejad et al., 2022) [:octocat:](https://github.com/UCDvision/PRANC)
```
@article{nooralinejad2022pranc,
  title={PRANC: Pseudo RAndom Networks for Compacting deep models},
  author={Nooralinejad, Parsa and Abbasi, Ali and Kolouri, Soheil and Pirsiavash, Hamed},
  journal={arXiv preprint arXiv:2206.08464},
  year={2022}
}
```

# Graph Neural Network
+ [Graph Condensation for Graph Neural Networks](https://arxiv.org/abs/2110.07580) (Wei Jin et al., ICLR2022) [:octocat:](https://github.com/chandlerbang/gcond)
```
@inproceedings{jin2022graph,
  title={Graph condensation for graph neural networks},
  author={Jin, Wei and Zhao, Lingxiao and Zhang, Shichang and Liu, Yozen and Tang, Jiliang and Shah, Neil},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2022}
}
```
+ [Condensing Graphs via One-Step Gradient Matching](https://arxiv.org/abs/2206.07746) (Wei Jin et al., KDD2022) [:octocat:](https://github.com/chandlerbang/gcond)
```
@inproceedings{jin2022condensing,
  title={Condensing Graphs via One-Step Gradient Matching},
  author={Jin, Wei and Tang, Xianfeng and Jiang, Haoming and Li, Zheng and Zhang, Danqing and Tang, Jiliang and Ying, Bin},
  booktitle={Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)},
  year={2022}
}
```
+ [Graph Condensation via Receptive Field Distribution Matching](https://arxiv.org/abs/2206.13697) (Mengyang Liu et al., 2022)
```
@article{liu2022graph,
  title={Graph Condensation via Receptive Field Distribution Matching},
  author={Liu, Mengyang and Li, Shanchuan and Chen, Xinshi and Song, Le},
  journal={arXiv preprint arXiv:2206.13697},
  year={2022}
}
```

# Neural Architecture Search
+ [Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data](https://arxiv.org/abs/1912.07768) (Felipe Petroski Such et al., ICML2020) [:octocat:](https://github.com/uber-research/GTN)
```
@inproceedings{such2020generative,
  title={Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data},
  author={Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth and Clune, Jeffrey},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={9206--9216},
  year={2020}
}
```

# Knowledge Distillation
+ [Knowledge Condensation Distillation](https://arxiv.org/abs/2207.05409) (Chenxin Li et al., ECCV2022) [:octocat:](https://github.com/dzy3/KCD)
```
@inproceedings{Li2022knowledge,
  title={Knowledge Condensation Distillation},
  author={Li, Chenxin and Lin, Mingbao and Ding, Zhiyuan and Lin, Nie and Zhuang, Yihong and Huang, Yue and Ding, Xinghao and Cao, Liujuan},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022}
}
```

# Medical
+ [Soft-Label Anonymous Gastric X-ray Image Distillation](https://arxiv.org/abs/2104.02857) (Guang Li et al., ICIP2020) [:octocat:](https://github.com/Guang000/Awesome-Dataset-Distillation)
```
@inproceedings{li2020soft,
  title={Soft-Label Anonymous Gastric X-Ray Image Distillation},
  author={Li, Guang and Togo, Ren and Ogawa, Takahiro and Haseyama, Miki},
  booktitle={Proceedings of the IEEE International Conference on Image Processing (ICIP)},
  pages={305--309},
  year={2020}
}
```
+ [Compressed Gastric Image Generation Based on Soft-Label Dataset Distillation for Medical Data Sharing](https://www.journals.elsevier.com/computer-methods-and-programs-in-biomedicine) (Guang Li et al., CMPB2022)
```
@article{li2022compressed,
  title={Compressed Gastric Image Generation Based on Soft-Label Dataset Distillation for Medical Data Sharing},
  author={Li, Guang and Togo, Ren and Ogawa, Takahiro and Haseyama, Miki},
  journal={Computer Methods and Programs in Biomedicine},
  year={2022}
}
```

# Fashion, Art, and Design
+ [Wearable ImageNet: Synthesizing Tileable Textures via Dataset Distillation](https://openaccess.thecvf.com/content/CVPR2022W/CVFAD/html/Cazenavette_Wearable_ImageNet_Synthesizing_Tileable_Textures_via_Dataset_Distillation_CVPRW_2022_paper.html) (George Cazenavette et al., CVPR2022 Workshop) [[Project Page]](https://georgecazenavette.github.io/mtt-distillation/) [:octocat:](https://github.com/georgecazenavette/mtt-distillation)
```
@inproceedings{cazenavette2022dataset,
  title={Dataset distillation by matching training trajectories},
  author={Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Workshop},
  year={2022}
}
```
